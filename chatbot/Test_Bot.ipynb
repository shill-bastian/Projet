{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a0cdf20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk, random,json, pickle\n",
    "import requests\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import numpy as np\n",
    "import os\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e23a5f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer=WordNetLemmatizer()\n",
    "context={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a498201",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Testing:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.intents= json.loads(open(\"intents.json\").read())\n",
    "        \n",
    "        data= pickle.load(open(\"training_data\",\"rb\"))\n",
    "        self.words= data[\"words\"]\n",
    "        self.classes= data[\"classes\"]\n",
    "        self.model= load_model(\"chatbot_model.h5\")\n",
    "        \n",
    "        self.ERROR_THRESHOLD=0.5\n",
    "        self.ignore_words= list(\"!@#$%^&*?\")\n",
    "        \n",
    "        \n",
    "    def clean_up_sentence(self, sentence):\n",
    "        \n",
    "        sentence_words= word_tokenize(sentence.lower())\n",
    "        \n",
    "        sentence_words= list(map(lemmatizer.lematizer, sentence_words))\n",
    "        sentence_words= list(filter(lambda x:x not in self.ignore_words, sentence_word))\n",
    "        return set(sentence_words)\n",
    "    \n",
    "    \n",
    "    def wordvector(self, sentence):\n",
    "        cv= CountVectorizer(tokenizer= lambda txt: txt.split())\n",
    "        sentence_words=\" \".join(self.clean_up_sentence(sentence))\n",
    "        words=\" \".join(self.words)\n",
    "        \n",
    "        vectorize= cv.fit([words])\n",
    "        word_vector= vectorize([sentence_words]).toarray().tolist()[0]\n",
    "        return np.array(word_vector)\n",
    "    \n",
    "    \n",
    "    def classify(self, sentence):\n",
    "        results= self.model.predict(np.array([self.wordvector(sentence)]))[0]\n",
    "        results= list(map(lambda x:[x[0], x[1]], enumerate(results)))\n",
    "        results= list(filter(lambda x:x[1] > self.ERROR_THRESHOLD, results))\n",
    "        \n",
    "        results.sort(key=lambda x:x[1], reverse=True)\n",
    "        return_list=[]\n",
    "        \n",
    "        for i in results:\n",
    "            return_list.append((self.classes[i[0]], str(i[1])))\n",
    "        return return_list\n",
    "    \n",
    "    \n",
    "    def results(self, sentence, userID):\n",
    "        if sentence.isdecimal():\n",
    "            if context[userID]== \"historydetails\":\n",
    "                return self.classify(\"ordernumber\")\n",
    "        return self.classify(sentence)\n",
    "    \n",
    "    def response(self, sentence, uerID=\"DianaStube\"):\n",
    "        results= self.results(sentence, userID)\n",
    "        print(sentence, results)\n",
    "        \n",
    "        ans=\"\"\n",
    "        if results:\n",
    "            while results:\n",
    "                for i in self.intents[\"intents\"]:\n",
    "                    if i[\"tag\"] == results[0][0]:\n",
    "                        if \"set\" in i and not \"filter\" in i:\n",
    "                            context[userID]= i[\"set\"]\n",
    "                        if not \"filter\" in i:\n",
    "                            ans= random.choice(i[\"responses\"])\n",
    "                            print(\"Query:\", sentence)\n",
    "                            print(\"Bot:\", ans)\n",
    "                        if userID in context and \"filter\" in i and i[\"filter\"]== context[userID]:\n",
    "                            if \"set\" in i:\n",
    "                                context[userID]= i[\"set\"]\n",
    "                            ans= random.choice(i[\"responses\"])\n",
    "                            \n",
    "                results.pop(0)   \n",
    "        return ans if ans!=\"\" else \"Sorry ! i don't know about\"  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e6dad6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8897dd1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e114571c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
