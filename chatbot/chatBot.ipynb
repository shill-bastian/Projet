{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c90b1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# creating a virtual assistant \n",
    "\n",
    "#talk package\n",
    "import pyttsx3 as ttx\n",
    "\n",
    "# listen package\n",
    "import speech_recognition as sr\n",
    "\n",
    "\n",
    "#predictions packages\n",
    "import json\n",
    "import numpy as np\n",
    "import pickle\n",
    "import random\n",
    "import nltk\n",
    "from  nltk.stem import WordNetLemmatizer\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b01438a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Assistant_SM:\n",
    "    def __init__(self):\n",
    "        #talk\n",
    "        self.engine= ttx.init()\n",
    "        self.voice= self.engine.getProperty(\"voices\")\n",
    "        self.engine.setProperty(\"voice\", (self.voice)[0].id)\n",
    "        \n",
    "        #listen\n",
    "        self.listener= sr.Recognizer()\n",
    "        self.voice_noted=\"\"\n",
    "        \n",
    "        #predictions attributes\n",
    "        \n",
    "        self.lemmatizer=WordNetLemmatizer()\n",
    "        #the json intents file  \n",
    "        # you can create a new one for you\n",
    "        self.intents=json.loads(open(\"intents.json\").read()) \n",
    "        # the lematized words of each  tag pattern  of json file \n",
    "        self.words= pickle.load(open(\"words.pkl\", \"rb\"))\n",
    "        self.classes=pickle.load(open(\"classes.pkl\", \"rb\"))\n",
    "        # the trained model\n",
    "        self.model= tf.keras.models.load_model(\"chatBot.h5\")\n",
    "        \n",
    "    #talk method\n",
    "    def A_talk(self, text):\n",
    "            self.engine.say(text)\n",
    "            self.engine.runAndWait()\n",
    "            \n",
    "    \n",
    "       \n",
    "    # the listener method\n",
    "    def A_listener(self):\n",
    "    \n",
    "        try:\n",
    "            with sr.Microphone() as source:\n",
    "                voix= (self.listener).listen(source)\n",
    "                self.voice_noted=(self.listener).recognize_google(voix, language=\"fr-FR\")\n",
    "                self.voice_noted.lower() \n",
    "                \n",
    "        except:\n",
    "            pass \n",
    "        return self.voice_noted \n",
    "    \n",
    "    # set of methods for predictions\n",
    "    \n",
    "    #1) mthod for lematization and tokenization\n",
    "    def A_clean(self,sentence):\n",
    "        sentence_words= nltk.word_tokenize(sentence)\n",
    "        sentence_words= [(self.lemmatizer).lemmatize(word) for word in sentence_words]\n",
    "        return sentence_words\n",
    "    \n",
    "    #2) set of words of the new sentence displayed \n",
    "    def A_bag(self, sentence):\n",
    "        sentence_words= self.A_clean(sentence)\n",
    "        bag= [0]*len(self.words)\n",
    "        for w in sentence_words:\n",
    "            for i , word in enumerate(self.words):\n",
    "                if word==w:\n",
    "                    bag[i]=1\n",
    "        return np.array(bag)\n",
    "    #3) method for probabilities predictions return the highest probabilities of a tag designed for a pattern\n",
    "    def A_pred_p(self,sentence):\n",
    "        bow= self.A_bag(sentence)\n",
    "        res= (self.model).predict(np.array([bow]))[0]\n",
    "        tsd=0.125\n",
    "        result=[[i,r] for i,r in enumerate(res) if r>tsd]\n",
    "        result.sort(key=lambda x:x[1], reverse=True)\n",
    "        result_list=[]\n",
    "        for r in result:\n",
    "            result_list.append({\"intent\":self.classes[r[0]], \"prob\":str(r[1])})\n",
    "        return result_list\n",
    "    \n",
    "    #4) the response method from chatbot \n",
    "    def A_getResponse(self ,intent_list, intents_json):\n",
    "        result=\"je ne comprends pas , veuillez reformuler\"\n",
    "        tag= intent_list[0][\"intent\"]\n",
    "        intents_list= intents_json[\"intents\"]\n",
    "        for i in intents_list:\n",
    "            if i[\"tag\"]==tag:\n",
    "                result=random.choice(i[\"responses\"])\n",
    "                break\n",
    "        return result "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b193992",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test the assistant\n",
    "Assistant = Assistant_SM()\n",
    "def launch_assistant(assistant):\n",
    "    print(\"enregistrement\")\n",
    "    message=Assistant.A_listener()\n",
    "    print(\"fin enregistrement\")\n",
    "    if assistant.voice_noted != \"\" :\n",
    "        print(message)\n",
    "        ints= Assistant.A_pred_p(message)\n",
    "        res= Assistant.A_getResponse(ints, Assistant.intents)\n",
    "        print(res)\n",
    "        Assistant.A_talk(res)\n",
    "        assistant.voice_noted = \"\"\n",
    "        \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2427a06c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enregistrement\n",
      "fin enregistrement\n",
      "ah bon ok pour samedi la liste\n",
      "1/1 [==============================] - 0s 278ms/step\n",
      " bonjour ravie de vous rencontrer \n",
      "enregistrement\n",
      "fin enregistrement\n",
      "enregistrement\n"
     ]
    }
   ],
   "source": [
    "\n",
    "while True:\n",
    "    launch_assistant(Assistant)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b03130",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08308ea2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30be7f96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c508b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "317854f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9ce401",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c97c3796",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc24be17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b6a7f0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "573b7b3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f597f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee076ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99861f65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd54e84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bfaa7bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "416a270f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
